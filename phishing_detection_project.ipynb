{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7697882,"sourceType":"datasetVersion","datasetId":4493131},{"sourceId":7699914,"sourceType":"datasetVersion","datasetId":4494569}],"dockerImageVersionId":30513,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detection of phishing websites using ML","metadata":{}},{"cell_type":"markdown","source":"## 1.Introduction to Notebook\n\nThis notebook was created as a part of a workshop in computational learning ,  a course me and my partner were partaking in Afeka College of Engineering . \n\nThe final assignment of this workshop is utilizing machine learning in a certain goal.\n\nMe, Niv Arad , and my partner, Omri Chen Yosef, were assigned to use ML in order to detect Phishing scams, as the open source dataset found on the web is not being updated fast enough and there is a need to classify benign website and spams quickly and reliably .\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 2. Objectives","metadata":{}},{"cell_type":"markdown","source":"A phishing site often employs social engineering tactics by imitating legitimate URLs and web pages. This project aims to develop machine learning and deep learning models using a specially compiled dataset for identifying phishing sites. The dataset includes both malicious phishing URLs and safe website URLs, from which necessary features based on URL and website content are derived. At the end we were trying a few different models , and compared them .","metadata":{}},{"cell_type":"markdown","source":"## 3. Data collections","metadata":{}},{"cell_type":"markdown","source":"The first step in this project was to find datasets that can serve our model. \n\nIn order to train our model we had to find to find dataset of both legitimate urls and phishing too.\n\nThe dataset of phishing url can be found from the opensource service called PhishTank.This dataset is getting updated daily. To download the data: **https://www.phishtank.com/developer_info.php**\n\nFor the legitimate URLs, we found a source that has a collection of benign and phishingURLs. The source of the dataset is Aalto University based in Finland, **https://research.aalto.fi/en/datasets/phishstorm-phishing-legitimate-url-dataset**. \nThe following dataset has the collections mentioned above merged , so we will need to make an extra step and drop all the rows of the urls who are not benign.\n\n** We decided not to use only the dataset obtained from the aalto universitt altough has benign and phishing urls , because it's not updated regulary as the phishtank url dataset","metadata":{}},{"cell_type":"markdown","source":"## 4. Collection of URL dataset","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Phishing urls dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.413195Z","iopub.execute_input":"2024-04-06T14:35:43.413634Z","iopub.status.idle":"2024-04-06T14:35:43.419464Z","shell.execute_reply.started":"2024-04-06T14:35:43.413591Z","shell.execute_reply":"2024-04-06T14:35:43.418256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phish_data = pd.read_csv(\"/kaggle/input/websites-datasets/verified_online.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.421530Z","iopub.execute_input":"2024-04-06T14:35:43.421938Z","iopub.status.idle":"2024-04-06T14:35:43.677611Z","shell.execute_reply.started":"2024-04-06T14:35:43.421904Z","shell.execute_reply":"2024-04-06T14:35:43.676325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phish_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.679602Z","iopub.execute_input":"2024-04-06T14:35:43.680277Z","iopub.status.idle":"2024-04-06T14:35:43.695930Z","shell.execute_reply.started":"2024-04-06T14:35:43.680241Z","shell.execute_reply":"2024-04-06T14:35:43.694637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phish_data.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.697453Z","iopub.execute_input":"2024-04-06T14:35:43.698006Z","iopub.status.idle":"2024-04-06T14:35:43.718135Z","shell.execute_reply.started":"2024-04-06T14:35:43.697973Z","shell.execute_reply":"2024-04-06T14:35:43.716809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phish_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.722127Z","iopub.execute_input":"2024-04-06T14:35:43.723322Z","iopub.status.idle":"2024-04-06T14:35:43.730330Z","shell.execute_reply.started":"2024-04-06T14:35:43.723272Z","shell.execute_reply":"2024-04-06T14:35:43.729279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Collecting 1000 Phishing URLs randomly\nphish_url = phish_data.sample(n = 40000, random_state = 12).copy()\nphish_url = phish_url.reset_index(drop=True)\nphish_url.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.731661Z","iopub.execute_input":"2024-04-06T14:35:43.732136Z","iopub.status.idle":"2024-04-06T14:35:43.779195Z","shell.execute_reply.started":"2024-04-06T14:35:43.732105Z","shell.execute_reply":"2024-04-06T14:35:43.778394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phish_url.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.780235Z","iopub.execute_input":"2024-04-06T14:35:43.781245Z","iopub.status.idle":"2024-04-06T14:35:43.787229Z","shell.execute_reply.started":"2024-04-06T14:35:43.781214Z","shell.execute_reply":"2024-04-06T14:35:43.786367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2. Legitimate urls dataset\n\n\nwe are loading only the first column because there is a problem loading all the file","metadata":{}},{"cell_type":"code","source":"legit_data = pd.read_csv(\"/kaggle/input/websites-datasets/urlset.csv\", encoding=\"ISO-8859-1\", usecols=[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:43.788234Z","iopub.execute_input":"2024-04-06T14:35:43.788968Z","iopub.status.idle":"2024-04-06T14:35:44.054894Z","shell.execute_reply.started":"2024-04-06T14:35:43.788938Z","shell.execute_reply":"2024-04-06T14:35:44.053837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legit_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.056567Z","iopub.execute_input":"2024-04-06T14:35:44.057055Z","iopub.status.idle":"2024-04-06T14:35:44.069070Z","shell.execute_reply.started":"2024-04-06T14:35:44.057008Z","shell.execute_reply":"2024-04-06T14:35:44.067816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legit_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.070583Z","iopub.execute_input":"2024-04-06T14:35:44.070962Z","iopub.status.idle":"2024-04-06T14:35:44.078874Z","shell.execute_reply.started":"2024-04-06T14:35:44.070931Z","shell.execute_reply":"2024-04-06T14:35:44.077467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Collecting 1000 Legitimate URLs randomly\nlegi_url = legit_data.sample(n = 40000, random_state = 12).copy()\nlegi_url = legi_url.reset_index(drop=True)\nlegi_url.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.083600Z","iopub.execute_input":"2024-04-06T14:35:44.084602Z","iopub.status.idle":"2024-04-06T14:35:44.107013Z","shell.execute_reply.started":"2024-04-06T14:35:44.084568Z","shell.execute_reply":"2024-04-06T14:35:44.105893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legi_url.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.108416Z","iopub.execute_input":"2024-04-06T14:35:44.108761Z","iopub.status.idle":"2024-04-06T14:35:44.115802Z","shell.execute_reply.started":"2024-04-06T14:35:44.108715Z","shell.execute_reply":"2024-04-06T14:35:44.114646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Feature Extraction\n","metadata":{}},{"cell_type":"markdown","source":"### 5.1. URL-based features","metadata":{}},{"cell_type":"markdown","source":"These will be the features we will extract from the url , we gathered those from the artical that was presented in class, more explaination will be following for every feature\n\n- domain of url\n- IP address in URL\n- length of url\n- depth of url\n- \"http/https\" in Domain\n- Using URL Shortening Services “TinyURL”\n- Count of prefix or sufix \"-\" in Domain\n- Count of prefix or sufix \"_\" in Domain\n- Sub-domain length\n- \"client\" in string\n- \"admin\" in string\n- \"login\" in string\n- \"server\" in string","metadata":{}},{"cell_type":"code","source":"# importing required packages for this section\nfrom urllib.parse import urlparse,urlencode\nimport ipaddress\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.117343Z","iopub.execute_input":"2024-04-06T14:35:44.117720Z","iopub.status.idle":"2024-04-06T14:35:44.125505Z","shell.execute_reply.started":"2024-04-06T14:35:44.117642Z","shell.execute_reply":"2024-04-06T14:35:44.124348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.1. Domain of url","metadata":{}},{"cell_type":"markdown","source":"We are just extracting the domain present in the URL. This feature doesn't have much significance in the training , because we the domain name alone can't give any indication of the type of website it is.","metadata":{}},{"cell_type":"code","source":"def getDomain(url):\n    domain = urlparse(url).netloc\n    if re.match(r\"^www.\",domain):\n        domain = domain.replace(\"www.\",\"\")\n    return domain","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.127248Z","iopub.execute_input":"2024-04-06T14:35:44.127647Z","iopub.status.idle":"2024-04-06T14:35:44.135899Z","shell.execute_reply.started":"2024-04-06T14:35:44.127615Z","shell.execute_reply":"2024-04-06T14:35:44.134942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.2. Length of URL","metadata":{}},{"cell_type":"markdown","source":"Phishing URLs may have excessively long domains or domain strings that appear unusual or unrelated to the legitimate domain.Longer domain names indicates phishing scams.","metadata":{}},{"cell_type":"code","source":"def lengthURL(url):\n    return len(url)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.137413Z","iopub.execute_input":"2024-04-06T14:35:44.137797Z","iopub.status.idle":"2024-04-06T14:35:44.146421Z","shell.execute_reply.started":"2024-04-06T14:35:44.137735Z","shell.execute_reply":"2024-04-06T14:35:44.145248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.3. Depth of URL","metadata":{}},{"cell_type":"markdown","source":"Computes the depth of the URL. This feature calculates the number of sub pages in the given url based on the '/'.\n\nThe value of feature is a numerical based on the URL.","metadata":{}},{"cell_type":"code","source":"def depthURL(url):\n    s = urlparse(url).path.split('/')\n    depth = 0\n    for j in range(len(s)):\n        if len(s[j])!=0:\n            depth = depth+1\n    return depth","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.148006Z","iopub.execute_input":"2024-04-06T14:35:44.148388Z","iopub.status.idle":"2024-04-06T14:35:44.160791Z","shell.execute_reply.started":"2024-04-06T14:35:44.148356Z","shell.execute_reply":"2024-04-06T14:35:44.159470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.4. \"http/https\" in Domain name","metadata":{}},{"cell_type":"markdown","source":"Checks for the presence of \"http/https\" in the domain part of the URL.The phishers add numerous times the \"https\" to the url in order to trick it's users and the make them feel like the website is legitimate as the https needs the ssl certificate which ensured the website owner identity.","metadata":{}},{"cell_type":"code","source":"def httpDomain(url):\n    if \"https\" in url:\n        return 1\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.164814Z","iopub.execute_input":"2024-04-06T14:35:44.165566Z","iopub.status.idle":"2024-04-06T14:35:44.173927Z","shell.execute_reply.started":"2024-04-06T14:35:44.165518Z","shell.execute_reply":"2024-04-06T14:35:44.172756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.5. URL shortening","metadata":{}},{"cell_type":"markdown","source":"URL shortening is a method on the “World Wide Web” in which a URL may be made considerably smaller in length and still lead to the required webpage. This is accomplished by means of an “HTTP Redirect” on a domain name that is short, which links to the webpage that has a long URL.\n\nIf the URL is using Shortening Services, the value assigned to this feature is 1 or else 0.","metadata":{}},{"cell_type":"code","source":"#listing shortening services\nshortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n                      r\"tr\\.im|link\\.zip\\.net\"","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.174964Z","iopub.execute_input":"2024-04-06T14:35:44.175285Z","iopub.status.idle":"2024-04-06T14:35:44.183046Z","shell.execute_reply.started":"2024-04-06T14:35:44.175258Z","shell.execute_reply":"2024-04-06T14:35:44.182199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tinyURL(url):\n    match = re.search(shortening_services,url)\n    if match:\n        return 1\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.184190Z","iopub.execute_input":"2024-04-06T14:35:44.185208Z","iopub.status.idle":"2024-04-06T14:35:44.195779Z","shell.execute_reply.started":"2024-04-06T14:35:44.185174Z","shell.execute_reply":"2024-04-06T14:35:44.194544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.6. Preffix or Suffix \"-\" in Domain","metadata":{}},{"cell_type":"markdown","source":"Phishing websites are crafted to mislead individuals into thinking they are on official sites, often mimicking the appearance of famous brands or institutions. A frequent trick used in these malicious domains is the strategic placement of a hyphen (\"-\") to fool users.\n\nThis tactic involves adding a hyphen to create a domain name that closely resembles the genuine domain it aims to mimic. For instance, instead of the authentic \"website.com,\" a phishing site might use \"web-site.com\" or \"websi-te.com.\" The goal behind using the hyphen is to take advantage of users who are not paying close attention or to capitalize on typosquatting, where users accidentally enter incorrect characters or misspell a real domain name.","metadata":{}},{"cell_type":"code","source":"def hyphenURL(url):\n    if '-' in urlparse(url).netloc:\n        return 1\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.197792Z","iopub.execute_input":"2024-04-06T14:35:44.198542Z","iopub.status.idle":"2024-04-06T14:35:44.205831Z","shell.execute_reply.started":"2024-04-06T14:35:44.198498Z","shell.execute_reply":"2024-04-06T14:35:44.204769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.7. Length of Sub-domain","metadata":{}},{"cell_type":"markdown","source":"Phishing URLs may have excessively long subdomains or subdomain strings that appear unusual or unrelated to the legitimate domain. For example, \"login.yourbank.com.phishingsite.com.\"","metadata":{}},{"cell_type":"code","source":"def subURl(url):\n    p = urlparse(url).path.split('.')\n    sub = 0\n    for j in range(len(p)):\n        if len(p[j])!=0:\n            sub = sub+1\n    return sub","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.207219Z","iopub.execute_input":"2024-04-06T14:35:44.207903Z","iopub.status.idle":"2024-04-06T14:35:44.219355Z","shell.execute_reply.started":"2024-04-06T14:35:44.207869Z","shell.execute_reply":"2024-04-06T14:35:44.218396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keywords in URL\n\nLook for keywords in the URL that suggest fraudulent activities, such as \"login\", \"client\", \"admin\", \"server\", or \"account.\" Phishing URLs often try to deceive users into believing they are accessing sensitive pages.","metadata":{}},{"cell_type":"markdown","source":"#### 5.1.8. search for keywords in url","metadata":{}},{"cell_type":"code","source":"def keyWordsURL(url):\n    keywords = [\"client\",\"login\",\"admin\",\"server\",\"account\"]\n    if any(word in url for word in keywords):\n        return 1\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.220842Z","iopub.execute_input":"2024-04-06T14:35:44.221608Z","iopub.status.idle":"2024-04-06T14:35:44.232072Z","shell.execute_reply.started":"2024-04-06T14:35:44.221573Z","shell.execute_reply":"2024-04-06T14:35:44.230816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2. Domain-based features","metadata":{}},{"cell_type":"markdown","source":"- DNS record\n- Age of domain\n- End period of domain","metadata":{}},{"cell_type":"code","source":"pip install python-whois","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:44.233729Z","iopub.execute_input":"2024-04-06T14:35:44.234210Z","iopub.status.idle":"2024-04-06T14:35:57.672364Z","shell.execute_reply.started":"2024-04-06T14:35:44.234167Z","shell.execute_reply":"2024-04-06T14:35:57.671102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# importing required packages for this section\nimport re\nfrom bs4 import BeautifulSoup\nimport whois\nimport urllib\nimport urllib.request\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.676911Z","iopub.execute_input":"2024-04-06T14:35:57.677302Z","iopub.status.idle":"2024-04-06T14:35:57.683554Z","shell.execute_reply.started":"2024-04-06T14:35:57.677262Z","shell.execute_reply":"2024-04-06T14:35:57.682451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.1. DNS record","metadata":{}},{"cell_type":"markdown","source":"For phishing websites, either the claimed identity is not recognized by the WHOIS database or no records founded for the hostname. If the DNS record is empty or not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).","metadata":{}},{"cell_type":"code","source":"# DNS Record availability (DNS_Record)\n# obtained in the featureExtraction function itself","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.684735Z","iopub.execute_input":"2024-04-06T14:35:57.685065Z","iopub.status.idle":"2024-04-06T14:35:57.695150Z","shell.execute_reply.started":"2024-04-06T14:35:57.685038Z","shell.execute_reply":"2024-04-06T14:35:57.694200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.2. Age of domain","metadata":{"execution":{"iopub.status.busy":"2023-07-05T12:53:42.665758Z","iopub.execute_input":"2023-07-05T12:53:42.666045Z","iopub.status.idle":"2023-07-05T12:53:42.67633Z","shell.execute_reply.started":"2023-07-05T12:53:42.666022Z","shell.execute_reply":"2023-07-05T12:53:42.67545Z"}}},{"cell_type":"markdown","source":"This feature can be extracted from WHOIS database. Most phishing websites live for a short period of time. The minimum age of the legitimate domain is considered to be 12 months for this project. Age here is nothing but different between creation and expiration time.\n\nIf age of domain > 12 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).","metadata":{}},{"cell_type":"code","source":"import whois\nfrom datetime import datetime\n\ndef domainAge(domain_name):\n    creation_date = domain_name.creation_date\n    expiration_date = domain_name.expiration_date\n    if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n        try:\n            creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n        except:\n            return 1\n    if ((expiration_date is None) or (creation_date is None)):\n        return 1\n    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n        return 1\n    else:\n        ageofdomain = abs((expiration_date - creation_date).days)\n        if ((ageofdomain/30) < 6):\n            age = 1\n        else:\n            age = 0\n    return age","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.696135Z","iopub.execute_input":"2024-04-06T14:35:57.696435Z","iopub.status.idle":"2024-04-06T14:35:57.710699Z","shell.execute_reply.started":"2024-04-06T14:35:57.696411Z","shell.execute_reply":"2024-04-06T14:35:57.709896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.3. End period of Domain","metadata":{}},{"cell_type":"markdown","source":"This feature can be extracted from WHOIS database. For this feature, the remaining domain time is calculated by finding the different between expiration time & current time. The end period considered for the legitimate domain is 6 months or less for this project.\n\nIf end period of domain > 6 months, the vlaue of this feature is 1 (phishing) else 0 (legitimate).","metadata":{}},{"cell_type":"code","source":"def domainEnd(domain_name):\n    expiration_date = domain_name.expiration_date\n    if isinstance(expiration_date,str):\n        try:\n            expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n        except:\n            return 1\n    if (expiration_date is None):\n        return 1\n    elif (type(expiration_date) is list):\n        return 1\n    else:\n        today = datetime.now()\n        end = abs((expiration_date - today).days)\n        if ((end/30) < 6):\n            end = 0\n        else:\n            end = 1\n    return end","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.712065Z","iopub.execute_input":"2024-04-06T14:35:57.712397Z","iopub.status.idle":"2024-04-06T14:35:57.722112Z","shell.execute_reply.started":"2024-04-06T14:35:57.712370Z","shell.execute_reply":"2024-04-06T14:35:57.721206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3. Content-based Features","metadata":{}},{"cell_type":"markdown","source":"- IFrame redirection\n- Webiste forwarding","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.1. IFrame redirection","metadata":{}},{"cell_type":"markdown","source":"IFrame is an HTML tag used to display an additional webpage into one that is currently shown. Phishers can make use of the “iframe” tag and make it invisible i.e. without frame borders. In this regard, phishers make use of the “frameBorder” attribute which causes the browser to render a visual delineation.\n\nIf the iframe is empty or repsonse is not found then, the value assigned to this feature is 1 (phishing) or else 0 (legitimate).","metadata":{}},{"cell_type":"code","source":"import requests\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.723573Z","iopub.execute_input":"2024-04-06T14:35:57.723891Z","iopub.status.idle":"2024-04-06T14:35:57.733987Z","shell.execute_reply.started":"2024-04-06T14:35:57.723864Z","shell.execute_reply":"2024-04-06T14:35:57.733123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iframe(response):\n    if response == \"\":\n        return 1\n    else:\n        if re.findall(r\"[|]\", response.text):\n            return 0\n        else:\n            return 1","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.745533Z","iopub.execute_input":"2024-04-06T14:35:57.745943Z","iopub.status.idle":"2024-04-06T14:35:57.751254Z","shell.execute_reply.started":"2024-04-06T14:35:57.745908Z","shell.execute_reply":"2024-04-06T14:35:57.750389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.3.2. Website forwarding","metadata":{}},{"cell_type":"markdown","source":"The fine line that distinguishes phishing websites from legitimate ones is how many times a website has been redirected. In our dataset, we find that legitimate websites have been redirected one time max. On the other hand, phishing websites containing this feature have been redirected at least 4 times.","metadata":{}},{"cell_type":"code","source":"def forwarding(response):\n    if response == \"\":\n        return 1\n    else:\n        if len(response.history) <= 2:\n            return 0\n        else:\n            return 1","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.752215Z","iopub.execute_input":"2024-04-06T14:35:57.752568Z","iopub.status.idle":"2024-04-06T14:35:57.762478Z","shell.execute_reply.started":"2024-04-06T14:35:57.752540Z","shell.execute_reply":"2024-04-06T14:35:57.761503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. URL feature extraction","metadata":{}},{"cell_type":"markdown","source":"Create a list and a function that calls the other functions and stores all the features of the URL in the list. We will extract the features of each URL and append to this list.","metadata":{}},{"cell_type":"code","source":"import time\ndef featureExtraction(url, label):\n    features = []\n    \n    start = time.time()\n    #URL-based feature\n    features.append(getDomain(url))\n    features.append(lengthURL(url))\n    features.append(depthURL(url))\n    features.append(httpDomain(url))\n    features.append(tinyURL(url))\n    features.append(hyphenURL(url))\n    features.append(subURl(url))\n    features.append(keyWordsURL(url))\n    end =time.time()\n    parsing = end-start\n    \n    features.append(label)\n\n    return (features,None)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.763893Z","iopub.execute_input":"2024-04-06T14:35:57.764241Z","iopub.status.idle":"2024-04-06T14:35:57.773047Z","shell.execute_reply.started":"2024-04-06T14:35:57.764213Z","shell.execute_reply":"2024-04-06T14:35:57.772303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.1. Legitimate URLs:\n\nFeature extraction is done on legitimate URLs.","metadata":{}},{"cell_type":"code","source":"legi_url.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.774562Z","iopub.execute_input":"2024-04-06T14:35:57.775256Z","iopub.status.idle":"2024-04-06T14:35:57.793821Z","shell.execute_reply.started":"2024-04-06T14:35:57.775196Z","shell.execute_reply":"2024-04-06T14:35:57.792820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting the features & storing them in a list\nlegi_features = []\nlabel = 0\nsum_parsing =0\nsum_domain = 0\nsum_content = 0\n\nfor i in range(0, 40000):\n    url = legi_url[\"domain\"][i]\n    try:\n        res = featureExtraction(url,label)\n        legi_features.append(res[0])\n    except:\n        print(\"there was a problem with line \",i ,\"the url is: \",url)\n    # print(legi_features)\n\nprint(\"Parsing : \",sum_parsing,\"\\nDomain :\",sum_domain,\"\\nContent :\",sum_content)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:35:57.795107Z","iopub.execute_input":"2024-04-06T14:35:57.795532Z","iopub.status.idle":"2024-04-06T14:36:00.394753Z","shell.execute_reply.started":"2024-04-06T14:35:57.795492Z","shell.execute_reply":"2024-04-06T14:36:00.393662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the list to dataframe\nfeature_name = [\"domain\",\"url_len\",\"url_dep\",\"httpDomain\",\"tinyURL\",\"hyphenURL\",\n                \"subURl\",\"keyWordURL\",\"label\"]\n\nlegitimate = pd.DataFrame(legi_features, columns=feature_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.396613Z","iopub.execute_input":"2024-04-06T14:36:00.397012Z","iopub.status.idle":"2024-04-06T14:36:00.572128Z","shell.execute_reply.started":"2024-04-06T14:36:00.396979Z","shell.execute_reply":"2024-04-06T14:36:00.571003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legitimate = legitimate.drop([\"domain\"], axis=1)\nlegitimate.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.573859Z","iopub.execute_input":"2024-04-06T14:36:00.574302Z","iopub.status.idle":"2024-04-06T14:36:00.590237Z","shell.execute_reply.started":"2024-04-06T14:36:00.574254Z","shell.execute_reply":"2024-04-06T14:36:00.589100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legitimate.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.591777Z","iopub.execute_input":"2024-04-06T14:36:00.592224Z","iopub.status.idle":"2024-04-06T14:36:00.603968Z","shell.execute_reply.started":"2024-04-06T14:36:00.592186Z","shell.execute_reply":"2024-04-06T14:36:00.602666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legitimate.to_csv('/kaggle/working/legitimate.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.605529Z","iopub.execute_input":"2024-04-06T14:36:00.605929Z","iopub.status.idle":"2024-04-06T14:36:00.786800Z","shell.execute_reply.started":"2024-04-06T14:36:00.605897Z","shell.execute_reply":"2024-04-06T14:36:00.785535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2. Phishing URLs:\n\nexctractig the features of the phishing urls took a lot of time, and also there are a few lines in the dataset which has a problem to be computed ,so i did this on my local machine and now i am adding the file to the datasets, its called \"phishing_finished\"","metadata":{}},{"cell_type":"markdown","source":"\n\n### 5.2.1 Phishing URLs:\nIf you choose to use the feature extraction in that mentioned before and it worked please continue this section:\n\nFeature extraction is done on phishing URLs.","metadata":{}},{"cell_type":"code","source":"phish_url.drop(phish_url.columns.difference(['url']), 1, inplace=True)\nphish_url.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.788469Z","iopub.execute_input":"2024-04-06T14:36:00.788887Z","iopub.status.idle":"2024-04-06T14:36:00.807280Z","shell.execute_reply.started":"2024-04-06T14:36:00.788852Z","shell.execute_reply":"2024-04-06T14:36:00.806160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"exctractig the features of the phishing urls took a lot of time, and also there are a few lines in the dataset which has a problem to be computed ,so i did this on my local machine and now i am adding the file to the datasets, its called \"phishing_finished\"","metadata":{}},{"cell_type":"code","source":"\n# #Extracting the features & storing them in a list\nphish_features = []\nlabel = 1\n\nsum_parsing =0\nsum_domain = 0\nsum_content = 0\nfor i in range(0, 40000):\n    url = phish_url[\"url\"][i]\n    res = featureExtraction(url,label)\n    phish_features.append(res[0])\n\n        \n#     # print(legi_features)\nprint(\"finished extracting features from phishing URLS\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:00.808546Z","iopub.execute_input":"2024-04-06T14:36:00.808994Z","iopub.status.idle":"2024-04-06T14:36:03.590945Z","shell.execute_reply.started":"2024-04-06T14:36:00.808952Z","shell.execute_reply":"2024-04-06T14:36:03.589801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.1 Phishing URLs:\nIf you choose to use the feature extraction in that mentioned before and it worked please continue this section:\n\nFeature extraction is done on phishing URLs.","metadata":{}},{"cell_type":"code","source":"# phish_features","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:03.592815Z","iopub.execute_input":"2024-04-06T14:36:03.593311Z","iopub.status.idle":"2024-04-06T14:36:03.598850Z","shell.execute_reply.started":"2024-04-06T14:36:03.593269Z","shell.execute_reply":"2024-04-06T14:36:03.597654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the list to dataframe\nfeature_name = [\"domain\",\"url_len\",\"url_dep\",\"httpDomain\",\"tinyURL\",\"hyphenURL\",\n                \"subURl\",\"keyWordURL\",\"label\"]\n\nphishing = pd.DataFrame(phish_features, columns=feature_name)\nphishing.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:03.599918Z","iopub.execute_input":"2024-04-06T14:36:03.600227Z","iopub.status.idle":"2024-04-06T14:36:03.786728Z","shell.execute_reply.started":"2024-04-06T14:36:03.600198Z","shell.execute_reply":"2024-04-06T14:36:03.785634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phishing.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:03.788205Z","iopub.execute_input":"2024-04-06T14:36:03.788538Z","iopub.status.idle":"2024-04-06T14:36:03.801333Z","shell.execute_reply.started":"2024-04-06T14:36:03.788509Z","shell.execute_reply":"2024-04-06T14:36:03.800297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# phishing = phishing.drop([\"domain\"], axis=1)\nphishing.to_csv('/kaggle/working/urldata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:03.802941Z","iopub.execute_input":"2024-04-06T14:36:03.803379Z","iopub.status.idle":"2024-04-06T14:36:04.057720Z","shell.execute_reply.started":"2024-04-06T14:36:03.803337Z","shell.execute_reply":"2024-04-06T14:36:04.056595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phishing.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.059322Z","iopub.execute_input":"2024-04-06T14:36:04.059802Z","iopub.status.idle":"2024-04-06T14:36:04.066361Z","shell.execute_reply.started":"2024-04-06T14:36:04.059734Z","shell.execute_reply":"2024-04-06T14:36:04.065272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.2 Phishing URLs:\nIf you chose not to use the feature extraction mentioned above or it not worked and got stuck  , you will need to load the data from the file we customly made in our local machine\n\n","metadata":{}},{"cell_type":"code","source":"# phishing = pd.read_csv(\"/kaggle/input/phishing-computed/final_phishing.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.068198Z","iopub.execute_input":"2024-04-06T14:36:04.068611Z","iopub.status.idle":"2024-04-06T14:36:04.075762Z","shell.execute_reply.started":"2024-04-06T14:36:04.068574Z","shell.execute_reply":"2024-04-06T14:36:04.074663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# phishing.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.077682Z","iopub.execute_input":"2024-04-06T14:36:04.078157Z","iopub.status.idle":"2024-04-06T14:36:04.085045Z","shell.execute_reply.started":"2024-04-06T14:36:04.078114Z","shell.execute_reply":"2024-04-06T14:36:04.083890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# phishing.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.087393Z","iopub.execute_input":"2024-04-06T14:36:04.087728Z","iopub.status.idle":"2024-04-06T14:36:04.095901Z","shell.execute_reply.started":"2024-04-06T14:36:04.087701Z","shell.execute_reply":"2024-04-06T14:36:04.094806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3. Final dataset","metadata":{}},{"cell_type":"markdown","source":"In the above section we formed two dataframes of legitimate & phishing URL features. Now, we will combine them to a single dataframe and export the data to csv file for the Machine Learning training done in other notebook","metadata":{}},{"cell_type":"code","source":"#Concatenating the dataframes into one \nurldata = pd.concat([legitimate, phishing]).reset_index(drop=True)\nurldata = urldata.sample(frac=1, random_state=1).reset_index(drop=True)\nurldata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.096997Z","iopub.execute_input":"2024-04-06T14:36:04.097309Z","iopub.status.idle":"2024-04-06T14:36:04.145103Z","shell.execute_reply.started":"2024-04-06T14:36:04.097283Z","shell.execute_reply":"2024-04-06T14:36:04.143968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.146406Z","iopub.execute_input":"2024-04-06T14:36:04.146706Z","iopub.status.idle":"2024-04-06T14:36:04.159387Z","shell.execute_reply.started":"2024-04-06T14:36:04.146681Z","shell.execute_reply":"2024-04-06T14:36:04.158239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.to_csv('/kaggle/working/urldata.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.160722Z","iopub.execute_input":"2024-04-06T14:36:04.161092Z","iopub.status.idle":"2024-04-06T14:36:04.546806Z","shell.execute_reply.started":"2024-04-06T14:36:04.161064Z","shell.execute_reply":"2024-04-06T14:36:04.545335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Loading final datastet","metadata":{"execution":{"iopub.status.busy":"2023-07-07T17:21:41.449888Z","iopub.execute_input":"2023-07-07T17:21:41.45024Z","iopub.status.idle":"2023-07-07T17:21:41.841205Z","shell.execute_reply.started":"2023-07-07T17:21:41.450215Z","shell.execute_reply":"2023-07-07T17:21:41.839814Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.548378Z","iopub.execute_input":"2024-04-06T14:36:04.548783Z","iopub.status.idle":"2024-04-06T14:36:04.555895Z","shell.execute_reply.started":"2024-04-06T14:36:04.548720Z","shell.execute_reply":"2024-04-06T14:36:04.554782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata = pd.read_csv(\"/kaggle/working/urldata.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.557653Z","iopub.execute_input":"2024-04-06T14:36:04.558244Z","iopub.status.idle":"2024-04-06T14:36:04.650779Z","shell.execute_reply.started":"2024-04-06T14:36:04.558202Z","shell.execute_reply":"2024-04-06T14:36:04.649603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata = urldata.drop([\"domain\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.652964Z","iopub.execute_input":"2024-04-06T14:36:04.653419Z","iopub.status.idle":"2024-04-06T14:36:04.666041Z","shell.execute_reply.started":"2024-04-06T14:36:04.653378Z","shell.execute_reply":"2024-04-06T14:36:04.665187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.667187Z","iopub.execute_input":"2024-04-06T14:36:04.667923Z","iopub.status.idle":"2024-04-06T14:36:04.686313Z","shell.execute_reply.started":"2024-04-06T14:36:04.667893Z","shell.execute_reply":"2024-04-06T14:36:04.685474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.687381Z","iopub.execute_input":"2024-04-06T14:36:04.688313Z","iopub.status.idle":"2024-04-06T14:36:04.704530Z","shell.execute_reply.started":"2024-04-06T14:36:04.688280Z","shell.execute_reply":"2024-04-06T14:36:04.703256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Data Preprocessing and EDA of the URL dataset","metadata":{}},{"cell_type":"markdown","source":"### 7.1. Shape of the dataet","metadata":{}},{"cell_type":"code","source":"urldata.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.706219Z","iopub.execute_input":"2024-04-06T14:36:04.707295Z","iopub.status.idle":"2024-04-06T14:36:04.716568Z","shell.execute_reply.started":"2024-04-06T14:36:04.707252Z","shell.execute_reply":"2024-04-06T14:36:04.715452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.2. Dataset Columns","metadata":{}},{"cell_type":"code","source":"urldata.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.718089Z","iopub.execute_input":"2024-04-06T14:36:04.718603Z","iopub.status.idle":"2024-04-06T14:36:04.728369Z","shell.execute_reply.started":"2024-04-06T14:36:04.718572Z","shell.execute_reply":"2024-04-06T14:36:04.727534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.3. Dataset information","metadata":{}},{"cell_type":"code","source":"urldata.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.729808Z","iopub.execute_input":"2024-04-06T14:36:04.730407Z","iopub.status.idle":"2024-04-06T14:36:04.755091Z","shell.execute_reply.started":"2024-04-06T14:36:04.730373Z","shell.execute_reply":"2024-04-06T14:36:04.754007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.4. Dataset Summary","metadata":{}},{"cell_type":"code","source":"urldata.describe","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.756681Z","iopub.execute_input":"2024-04-06T14:36:04.757694Z","iopub.status.idle":"2024-04-06T14:36:04.768332Z","shell.execute_reply.started":"2024-04-06T14:36:04.757661Z","shell.execute_reply":"2024-04-06T14:36:04.767255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above obtained result shows that the most of the data is made of 0's & 1's except 'Domain' & 'URL_Depth' columns. The Domain column doesnt have any significance to the machine learning model training. So dropping the 'Domain' column from the dataset.","metadata":{}},{"cell_type":"markdown","source":"### 7.5.Check of Null values","metadata":{}},{"cell_type":"code","source":"urldata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.770067Z","iopub.execute_input":"2024-04-06T14:36:04.770508Z","iopub.status.idle":"2024-04-06T14:36:04.782668Z","shell.execute_reply.started":"2024-04-06T14:36:04.770467Z","shell.execute_reply":"2024-04-06T14:36:04.781640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the feature extraction file, the extracted features of legitmate & phishing url datasets are just concatenated without any shuffling. This resulted in top 1000 rows of legitimate url data & bottom 1000 of phishing url data.","metadata":{}},{"cell_type":"code","source":"urldata.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.784059Z","iopub.execute_input":"2024-04-06T14:36:04.784623Z","iopub.status.idle":"2024-04-06T14:36:04.794005Z","shell.execute_reply.started":"2024-04-06T14:36:04.784592Z","shell.execute_reply":"2024-04-06T14:36:04.793130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.7. Max and Min of \"url_len\"","metadata":{}},{"cell_type":"code","source":"print(\"Maximum of url length::\",urldata[\"url_len\"].max())\nprint(\"Minimum of url length::\",urldata[\"url_len\"].min())","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.795449Z","iopub.execute_input":"2024-04-06T14:36:04.796102Z","iopub.status.idle":"2024-04-06T14:36:04.804612Z","shell.execute_reply.started":"2024-04-06T14:36:04.796070Z","shell.execute_reply":"2024-04-06T14:36:04.803509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.8. Max and Min of \"url_depth\"","metadata":{}},{"cell_type":"code","source":"print(\"Maximum of url depth::\",urldata[\"url_dep\"].max())\nprint(\"Minimum of url length::\",urldata[\"url_dep\"].min())","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.808116Z","iopub.execute_input":"2024-04-06T14:36:04.808740Z","iopub.status.idle":"2024-04-06T14:36:04.816051Z","shell.execute_reply.started":"2024-04-06T14:36:04.808708Z","shell.execute_reply":"2024-04-06T14:36:04.815255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Data Visualization ","metadata":{}},{"cell_type":"markdown","source":"### 8.1. Plotting the data distribution","metadata":{}},{"cell_type":"code","source":"urldata.hist(bins = 50,figsize = (15,15))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:04.817485Z","iopub.execute_input":"2024-04-06T14:36:04.818679Z","iopub.status.idle":"2024-04-06T14:36:07.711683Z","shell.execute_reply.started":"2024-04-06T14:36:04.818648Z","shell.execute_reply":"2024-04-06T14:36:07.710447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8.2. Correlation heatmap","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(15,13))\n# sns.heatmap(urldata.corr())\n# plt.show()\n\nplt.figure(figsize=(15,13))\ncor = np.abs(urldata.corr())\nsns.heatmap(cor, annot=True,cmap=plt.cm.Greens, vmin=-1, vmax=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:36:07.713561Z","iopub.execute_input":"2024-04-06T14:36:07.714834Z","iopub.status.idle":"2024-04-06T14:36:08.348544Z","shell.execute_reply.started":"2024-04-06T14:36:07.714790Z","shell.execute_reply":"2024-04-06T14:36:08.347552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.3 Regplot","metadata":{}},{"cell_type":"markdown","source":"## 9. Splitting the Dataset","metadata":{}},{"cell_type":"code","source":"y = urldata['label']\nX = urldata.drop('label',axis=1)\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:26.667894Z","iopub.execute_input":"2024-04-06T14:40:26.668290Z","iopub.status.idle":"2024-04-06T14:40:26.680748Z","shell.execute_reply.started":"2024-04-06T14:40:26.668262Z","shell.execute_reply":"2024-04-06T14:40:26.679496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into train and test sets: 70-30 split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.4, random_state = 12)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:28.611863Z","iopub.execute_input":"2024-04-06T14:40:28.612638Z","iopub.status.idle":"2024-04-06T14:40:28.701946Z","shell.execute_reply.started":"2024-04-06T14:40:28.612599Z","shell.execute_reply":"2024-04-06T14:40:28.700781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. Machine Learning models and Training","metadata":{}},{"cell_type":"markdown","source":"This data set comes under classification problem, as the input URL is classified as phishing (1) or legitimate (0). The supervised machine learning models (classification) considered to train the dataset:\n\n- Decision Tree\n- Random Forest\n- XGBoost\n- Logistic Regression\n- Support Vectore Machines (SVM)\n- Multilayer perceptrons\n- Autoencoder Neural Network","metadata":{}},{"cell_type":"code","source":"#importing packages\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:34.618437Z","iopub.execute_input":"2024-04-06T14:40:34.618895Z","iopub.status.idle":"2024-04-06T14:40:34.624048Z","shell.execute_reply.started":"2024-04-06T14:40:34.618860Z","shell.execute_reply":"2024-04-06T14:40:34.622834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating holders to store the model performance results\nML_Model = []\nacc_train = []\nacc_test = []\n\n#function to call for storing the results\ndef storeResults(model, a,b):\n    ML_Model.append(model)\n    acc_train.append(round(a, 3))\n    acc_test.append(round(b, 3))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:37.139671Z","iopub.execute_input":"2024-04-06T14:40:37.140208Z","iopub.status.idle":"2024-04-06T14:40:37.148702Z","shell.execute_reply.started":"2024-04-06T14:40:37.140163Z","shell.execute_reply":"2024-04-06T14:40:37.147357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.1. Decision Tree Classifier","metadata":{}},{"cell_type":"markdown","source":"Decision trees are widely used models for classification and regression tasks. Essentially, they learn a hierarchy of if/else questions, leading to a decision. Learning a decision tree means learning the sequence of if/else questions that gets us to the true answer most quickly.\n\nIn the machine learning setting, these questions are called tests (not to be confused with the test set, which is the data we use to test to see how generalizable our model is). To build a tree, the algorithm searches over all possible tests and finds the one that is most informative about the target variable.","metadata":{}},{"cell_type":"code","source":"# Decision Tree model \nfrom sklearn.tree import DecisionTreeClassifier\n\n# instantiate the model \ntree = DecisionTreeClassifier(max_depth = 5)\n# fit the model \ntree.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.637799Z","iopub.status.idle":"2024-04-06T14:39:36.638335Z","shell.execute_reply.started":"2024-04-06T14:39:36.638057Z","shell.execute_reply":"2024-04-06T14:39:36.638082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_tree = tree.predict(X_test)\ny_train_tree = tree.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.640319Z","iopub.status.idle":"2024-04-06T14:39:36.640915Z","shell.execute_reply.started":"2024-04-06T14:39:36.640609Z","shell.execute_reply":"2024-04-06T14:39:36.640635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_tree = accuracy_score(y_train,y_train_tree)\nacc_test_tree = accuracy_score(y_test,y_test_tree)\n\nprint(\"Decision Tree: Accuracy on training Data: {:.3f}\".format(acc_train_tree))\nprint(\"Decision Tree: Accuracy on test Data: {:.3f}\".format(acc_test_tree))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.642515Z","iopub.status.idle":"2024-04-06T14:39:36.643086Z","shell.execute_reply.started":"2024-04-06T14:39:36.642805Z","shell.execute_reply":"2024-04-06T14:39:36.642833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#checking the feature improtance in the model\nplt.figure(figsize=(9,7))\nn_features = X_train.shape[1]\nplt.barh(range(n_features), tree.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), X_train.columns)\nplt.xlabel(\"Feature importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.644571Z","iopub.status.idle":"2024-04-06T14:39:36.646071Z","shell.execute_reply.started":"2024-04-06T14:39:36.645856Z","shell.execute_reply":"2024-04-06T14:39:36.645878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Results:","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Decision Tree', acc_train_tree, acc_test_tree)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.647299Z","iopub.status.idle":"2024-04-06T14:39:36.647961Z","shell.execute_reply.started":"2024-04-06T14:39:36.647740Z","shell.execute_reply":"2024-04-06T14:39:36.647776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.2. Random Forest","metadata":{}},{"cell_type":"markdown","source":"Random forests for regression and classification are currently among the most widely used machine learning methods.A random forest is essentially a collection of decision trees, where each tree is slightly different from the others. The idea behind random forests is that each tree might do a relatively good job of predicting, but will likely overfit on part of the data.\n\nIf we build many trees, all of which work well and overfit in different ways, we can reduce the amount of overfitting by averaging their results. To build a random forest model, you need to decide on the number of trees to build (the n_estimators parameter of RandomForestRegressor or RandomForestClassifier). They are very powerful, often work well without heavy tuning of the parameters, and don’t require scaling of the data.","metadata":{}},{"cell_type":"code","source":"# Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# instantiate the model\nforest = RandomForestClassifier(max_depth=16)\n\n# fit the model \nforest.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:42.379348Z","iopub.execute_input":"2024-04-06T14:40:42.379779Z","iopub.status.idle":"2024-04-06T14:40:45.105391Z","shell.execute_reply.started":"2024-04-06T14:40:42.379724Z","shell.execute_reply":"2024-04-06T14:40:45.104253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_forest = forest.predict(X_test)\ny_train_forest = forest.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:47.228248Z","iopub.execute_input":"2024-04-06T14:40:47.228920Z","iopub.status.idle":"2024-04-06T14:40:47.983471Z","shell.execute_reply.started":"2024-04-06T14:40:47.228873Z","shell.execute_reply":"2024-04-06T14:40:47.982241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"\n#computing the accuracy of the model performance\nacc_train_forest = accuracy_score(y_train,y_train_forest)\nacc_test_forest = accuracy_score(y_test,y_test_forest)\n\nprint(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\nprint(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:51.748316Z","iopub.execute_input":"2024-04-06T14:40:51.748714Z","iopub.status.idle":"2024-04-06T14:40:51.767079Z","shell.execute_reply.started":"2024-04-06T14:40:51.748685Z","shell.execute_reply":"2024-04-06T14:40:51.765592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the feature improtance in the model\nplt.figure(figsize=(9,7))\nn_features = X_train.shape[1]\nplt.barh(range(n_features), forest.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), X_train.columns)\nplt.xlabel(\"Feature importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:40:58.003551Z","iopub.execute_input":"2024-04-06T14:40:58.003982Z","iopub.status.idle":"2024-04-06T14:40:58.315619Z","shell.execute_reply.started":"2024-04-06T14:40:58.003947Z","shell.execute_reply":"2024-04-06T14:40:58.314445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Results","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Random Forest', acc_train_forest, acc_test_forest)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.656892Z","iopub.status.idle":"2024-04-06T14:39:36.657625Z","shell.execute_reply.started":"2024-04-06T14:39:36.657404Z","shell.execute_reply":"2024-04-06T14:39:36.657425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.3. XGBoost","metadata":{}},{"cell_type":"markdown","source":"XGBoost is one of the most popular machine learning algorithms these days. XGBoost stands for eXtreme Gradient Boosting. Regardless of the type of prediction task at hand; regression or classification. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance.","metadata":{}},{"cell_type":"code","source":"#XGBoost Classification model\nfrom xgboost import XGBClassifier\n\n# instantiate the model\nxgb = XGBClassifier(learning_rate=0.4,max_depth=7)\n#fit the model\nxgb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.658847Z","iopub.status.idle":"2024-04-06T14:39:36.659517Z","shell.execute_reply.started":"2024-04-06T14:39:36.659306Z","shell.execute_reply":"2024-04-06T14:39:36.659332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_xgb = xgb.predict(X_test)\ny_train_xgb = xgb.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.660689Z","iopub.status.idle":"2024-04-06T14:39:36.661353Z","shell.execute_reply.started":"2024-04-06T14:39:36.661149Z","shell.execute_reply":"2024-04-06T14:39:36.661169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_xgb = accuracy_score(y_train,y_train_xgb)\nacc_test_xgb = accuracy_score(y_test,y_test_xgb)\n\nprint(\"XGBoost: Accuracy on training Data: {:.3f}\".format(acc_train_xgb))\nprint(\"XGBoost : Accuracy on test Data: {:.3f}\".format(acc_test_xgb))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.662503Z","iopub.status.idle":"2024-04-06T14:39:36.663174Z","shell.execute_reply.started":"2024-04-06T14:39:36.662951Z","shell.execute_reply":"2024-04-06T14:39:36.662971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Results","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('XGBoost', acc_train_xgb, acc_test_xgb)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.664342Z","iopub.status.idle":"2024-04-06T14:39:36.665005Z","shell.execute_reply.started":"2024-04-06T14:39:36.664802Z","shell.execute_reply":"2024-04-06T14:39:36.664822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.4. Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"In machine learning, logistic regression is a classification algorithm used to model the relationship between input features and a binary output variable. It estimates the probability of the output belonging to a specific class using a logistic or sigmoid function.\nDuring training, it learns optimal parameters by minimizing a cost function, such as cross-entropy loss. Once trained, it can make predictions on new data by calculating the probability of belonging to a class. Logistic regression is widely used in various domains for binary classification tasks when a linear relationship is assumed.","metadata":{}},{"cell_type":"code","source":"#Logistic regression machine learning\n\nfrom sklearn.linear_model import LogisticRegression\n\n#instantive the model\nlogistic = LogisticRegression(random_state=12, max_iter=1000)\n#fit the model\nlogistic.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:41:21.665677Z","iopub.execute_input":"2024-04-06T14:41:21.666120Z","iopub.status.idle":"2024-04-06T14:41:22.198995Z","shell.execute_reply.started":"2024-04-06T14:41:21.666085Z","shell.execute_reply":"2024-04-06T14:41:22.197581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_log = logistic.predict(X_test)\ny_train_log = logistic.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:41:26.994994Z","iopub.execute_input":"2024-04-06T14:41:26.995376Z","iopub.status.idle":"2024-04-06T14:41:27.015354Z","shell.execute_reply.started":"2024-04-06T14:41:26.995347Z","shell.execute_reply":"2024-04-06T14:41:27.013738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_log = accuracy_score(y_train,y_train_log)\nacc_test_log = accuracy_score(y_test,y_test_log)\n\nprint(\"Logistic: Accuracy on training Data: {:.3f}\".format(acc_train_log))\nprint(\"Logistic : Accuracy on test Data: {:.3f}\".format(acc_test_log))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:41:29.202705Z","iopub.execute_input":"2024-04-06T14:41:29.203183Z","iopub.status.idle":"2024-04-06T14:41:29.220296Z","shell.execute_reply.started":"2024-04-06T14:41:29.203148Z","shell.execute_reply":"2024-04-06T14:41:29.219137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Result","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Logistic', acc_train_log, acc_test_log)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.671571Z","iopub.status.idle":"2024-04-06T14:39:36.672257Z","shell.execute_reply.started":"2024-04-06T14:39:36.672046Z","shell.execute_reply":"2024-04-06T14:39:36.672066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.5. Support Vector Machines","metadata":{}},{"cell_type":"markdown","source":"In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier.","metadata":{}},{"cell_type":"code","source":"#Support vector machine model\nfrom sklearn.svm import SVC\n\n# instantiate the model\nsvm = SVC(kernel='linear', C=1.0, random_state=12)\n#fit the model\nsvm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.673395Z","iopub.status.idle":"2024-04-06T14:39:36.674048Z","shell.execute_reply.started":"2024-04-06T14:39:36.673846Z","shell.execute_reply":"2024-04-06T14:39:36.673866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_svm = svm.predict(X_test)\ny_train_svm = svm.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.675237Z","iopub.status.idle":"2024-04-06T14:39:36.675653Z","shell.execute_reply.started":"2024-04-06T14:39:36.675440Z","shell.execute_reply":"2024-04-06T14:39:36.675460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_svm = accuracy_score(y_train,y_train_svm)\nacc_test_svm = accuracy_score(y_test,y_test_svm)\n\nprint(\"SVM: Accuracy on training Data: {:.3f}\".format(acc_train_svm))\nprint(\"SVM : Accuracy on test Data: {:.3f}\".format(acc_test_svm))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.676767Z","iopub.status.idle":"2024-04-06T14:39:36.677158Z","shell.execute_reply.started":"2024-04-06T14:39:36.676963Z","shell.execute_reply":"2024-04-06T14:39:36.676982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Result","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('SVM', acc_train_svm, acc_test_svm)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.678577Z","iopub.status.idle":"2024-04-06T14:39:36.678984Z","shell.execute_reply.started":"2024-04-06T14:39:36.678794Z","shell.execute_reply":"2024-04-06T14:39:36.678813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.6. Multilayer Perceptrons (MLPs)","metadata":{}},{"cell_type":"markdown","source":"Multilayer perceptrons (MLPs) are also known as (vanilla) feed-forward neural networks, or sometimes just neural networks. Multilayer perceptrons can be applied for both classification and regression problems.\n\nMLPs can be viewed as generalizations of linear models that perform multiple stages of processing to come to a decision.","metadata":{}},{"cell_type":"code","source":"# Multilayer Perceptrons model\nfrom sklearn.neural_network import MLPClassifier\n\n# instantiate the model\nmlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n\n# fit the model \nmlp.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.681140Z","iopub.status.idle":"2024-04-06T14:39:36.681924Z","shell.execute_reply.started":"2024-04-06T14:39:36.681636Z","shell.execute_reply":"2024-04-06T14:39:36.681666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_mlp = mlp.predict(X_test)\ny_train_mlp = mlp.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.683137Z","iopub.status.idle":"2024-04-06T14:39:36.683530Z","shell.execute_reply.started":"2024-04-06T14:39:36.683339Z","shell.execute_reply":"2024-04-06T14:39:36.683358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance Evaluation","metadata":{}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_mlp = accuracy_score(y_train,y_train_mlp)\nacc_test_mlp = accuracy_score(y_test,y_test_mlp)\n\nprint(\"Multilayer Perceptrons: Accuracy on training Data: {:.3f}\".format(acc_train_mlp))\nprint(\"Multilayer Perceptrons: Accuracy on test Data: {:.3f}\".format(acc_test_mlp))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.685304Z","iopub.status.idle":"2024-04-06T14:39:36.685688Z","shell.execute_reply.started":"2024-04-06T14:39:36.685500Z","shell.execute_reply":"2024-04-06T14:39:36.685519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing Result","metadata":{}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Multilayer Perceptrons', acc_train_mlp, acc_test_mlp)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.686898Z","iopub.status.idle":"2024-04-06T14:39:36.687297Z","shell.execute_reply.started":"2024-04-06T14:39:36.687095Z","shell.execute_reply":"2024-04-06T14:39:36.687113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11. Perfect Score - Dropping Features","metadata":{}},{"cell_type":"markdown","source":"After consulation with our mentor Amit Shtekel and explaining him we received a perfect score for our models (1.00) , he gave us new assignment , and it is to compare the price of extracting each feature. After we will drop the expensive features we will need to check the model again and to see it's results.\n\nWe decided to measure the run time of the features after we grouped them to categories , parsing , domain and dns registery, content.\nAfter a few runtime measures we have seen that the extraction of the domain and dns registeries are much more expensive - for 1000 rows the parsing features  took 0.09 sec and the content features took 0.9 seconds , but the domain/dns features took 620 seconds(!!) , compared to the other features combined it is more than 620 times .","metadata":{}},{"cell_type":"markdown","source":"## 12. Dropping the domain/dns features ","metadata":{}},{"cell_type":"markdown","source":"## 12.1 Loading the Data","metadata":{}},{"cell_type":"code","source":"urldata = pd.read_csv(\"/kaggle/working/urldata.csv\")\nurldata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.688481Z","iopub.status.idle":"2024-04-06T14:39:36.688907Z","shell.execute_reply.started":"2024-04-06T14:39:36.688681Z","shell.execute_reply":"2024-04-06T14:39:36.688699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.2 Dropping Features","metadata":{}},{"cell_type":"code","source":"urldata = urldata.drop([\"dns\"], axis=1)\nurldata = urldata.drop([\"domainAge\"], axis=1)\nurldata = urldata.drop([\"domainEnd\"], axis=1)\nurldata = urldata.drop([\"iframe\"], axis=1)\nurldata = urldata.drop([\"forwarding\"], axis=1)\nurldata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.690137Z","iopub.status.idle":"2024-04-06T14:39:36.690519Z","shell.execute_reply.started":"2024-04-06T14:39:36.690333Z","shell.execute_reply":"2024-04-06T14:39:36.690352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 13.Training Models","metadata":{}},{"cell_type":"markdown","source":"## 13.1 Splitting the Data","metadata":{}},{"cell_type":"code","source":"y = urldata['label']\nX = urldata.drop('label',axis=1)\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.691420Z","iopub.status.idle":"2024-04-06T14:39:36.691854Z","shell.execute_reply.started":"2024-04-06T14:39:36.691609Z","shell.execute_reply":"2024-04-06T14:39:36.691627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into train and test sets: 70-30 split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.3, random_state = 42)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.693475Z","iopub.status.idle":"2024-04-06T14:39:36.693903Z","shell.execute_reply.started":"2024-04-06T14:39:36.693676Z","shell.execute_reply":"2024-04-06T14:39:36.693695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"# Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# instantiate the model\nforest = RandomForestClassifier(max_depth=5)\n\n# fit the model \nforest.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.695206Z","iopub.status.idle":"2024-04-06T14:39:36.695589Z","shell.execute_reply.started":"2024-04-06T14:39:36.695401Z","shell.execute_reply":"2024-04-06T14:39:36.695419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_forest = forest.predict(X_test)\ny_train_forest = forest.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.697134Z","iopub.status.idle":"2024-04-06T14:39:36.697648Z","shell.execute_reply.started":"2024-04-06T14:39:36.697440Z","shell.execute_reply":"2024-04-06T14:39:36.697463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#computing the accuracy of the model performance\nacc_train_forest = accuracy_score(y_train,y_train_forest)\nacc_test_forest = accuracy_score(y_test,y_test_forest)\n\nprint(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\nprint(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.698826Z","iopub.status.idle":"2024-04-06T14:39:36.699226Z","shell.execute_reply.started":"2024-04-06T14:39:36.699031Z","shell.execute_reply":"2024-04-06T14:39:36.699049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"#Logistic regression machine learning\n\nfrom sklearn.linear_model import LogisticRegression\n\n#instantive the model\nlogistic = LogisticRegression(random_state=42, max_iter=1000)\n#fit the model\nlogistic.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.700193Z","iopub.status.idle":"2024-04-06T14:39:36.700568Z","shell.execute_reply.started":"2024-04-06T14:39:36.700383Z","shell.execute_reply":"2024-04-06T14:39:36.700401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_ogisticl = logistic.predict(X_test)\ny_train_logistic = logistic.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.701597Z","iopub.status.idle":"2024-04-06T14:39:36.701960Z","shell.execute_reply.started":"2024-04-06T14:39:36.701783Z","shell.execute_reply":"2024-04-06T14:39:36.701800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#computing the accuracy of the model performance\nacc_train_logistic = accuracy_score(y_train,y_train_logistic)\nacc_test_logistic = accuracy_score(y_test,y_test_ogisticl)\n\nprint(\"Logistic Regression: Accuracy on training Data: {:.3f}\".format(acc_train_logistic))\nprint(\"Logistic Regression: Accuracy on test Data: {:.3f}\".format(acc_test_logistic))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:39:36.702960Z","iopub.status.idle":"2024-04-06T14:39:36.703317Z","shell.execute_reply.started":"2024-04-06T14:39:36.703128Z","shell.execute_reply":"2024-04-06T14:39:36.703145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}